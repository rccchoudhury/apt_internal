{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11babb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from timm.data import create_transform\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from src.data.transforms import transforms_imagenet_eval\n",
    "from src.models.entropy_utils import select_patches_by_threshold, visualize_selected_patches_cv2\n",
    "\n",
    "split = \"val\"\n",
    "image_size = 512\n",
    "data_dir = os.path.join(\"/edrive1/rchoudhu/ILSVRC2012\", split)\n",
    "\n",
    "val_transform = transforms_imagenet_eval(img_size=image_size)\n",
    "data_val = datasets.ImageFolder(\n",
    "    root=f\"{data_dir}\",\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "unnorm = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "    std=[1/0.229, 1/0.224, 1/0.225]\n",
    ")\n",
    "\n",
    "\n",
    "img, label = data_val[28582]\n",
    "# Undo imagenet norm, then permute dims. \n",
    "img = unnorm(img).permute(1,2,0)\n",
    "\n",
    "print(\"Image shape: \", img.shape)\n",
    "img_vis = np.array(img*255).astype(np.uint8)\n",
    "img_vis = Image.fromarray(img_vis)\n",
    "img_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193600a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W, C = img.shape\n",
    "\n",
    "img_tensor = img.permute(2, 0, 1).unsqueeze(0)\n",
    "img_down2 = F.interpolate(img_tensor, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "img_down4 = F.interpolate(img_tensor, scale_factor=0.25, mode='bilinear', align_corners=False)\n",
    "#  Upsample back up \n",
    "img_up2 = F.interpolate(img_down2, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "img_up4 = F.interpolate(img_down4, scale_factor=4, mode='bilinear', align_corners=False)\n",
    "\n",
    "img_vis = img_up2.squeeze(0).permute(1, 2, 0).numpy()\n",
    "img_vis = np.array(img_vis*255).astype(np.uint8)\n",
    "img_vis = Image.fromarray(img_vis)\n",
    "\n",
    "\n",
    "patch_size = 16\n",
    "mse_map = F.mse_loss(img_tensor, img_up2, reduction='none').squeeze(0).permute(1, 2, 0)\n",
    "patches16 = mse_map.unfold(0, patch_size, patch_size).unfold(1, patch_size, patch_size)\n",
    "\n",
    "patch_size = 32\n",
    "mse_map = F.mse_loss(img_tensor, img_up2, reduction='none').squeeze(0).permute(1, 2, 0)\n",
    "patches = mse_map.unfold(0, patch_size, patch_size).unfold(1, patch_size, patch_size)\n",
    "\n",
    "patch_size = 64\n",
    "mse_map = F.mse_loss(img_tensor, img_up4, reduction='none').squeeze(0).permute(1, 2, 0)\n",
    "patches64 = mse_map.unfold(0, patch_size, patch_size).unfold(1, patch_size, patch_size)\n",
    "\n",
    "print(\"MSE map shape: \", mse_map.shape)\n",
    "print(\"pathces shape: \", patches.shape)\n",
    "print(\"patch16 shape: \", patches16.shape)\n",
    "print(\"patch64 shape: \", patches64.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf05c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = patches.mean(dim=(3, 4)).mean(-1).unsqueeze(0)\n",
    "responses16 = patches16.mean(dim=(3, 4)).mean(-1).unsqueeze(0)\n",
    "responses64 = patches64.mean(dim=(3, 4)).mean(-1).unsqueeze(0)\n",
    "\n",
    "response_map = {16: responses16, 32: responses, 64: responses64}\n",
    "\n",
    "masks =select_patches_by_threshold(response_map, thresholds=[0.0001, 0.0001])\n",
    "for k, mask in masks.items():\n",
    "    masks[k] = mask.squeeze()\n",
    "\n",
    "num_tokens = sum([m.sum().int().item() for _, m in masks.items()])\n",
    "num_base_tokens = masks[16].numel()\n",
    "\n",
    "print(\"Fraction retained: {}\".format(num_tokens / num_base_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0256f33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_img = visualize_selected_patches_cv2(\n",
    "    img_tensor[0]*255, \n",
    "    masks=masks,\n",
    "    patch_sizes=list(masks.keys()),\n",
    "    color=(128,128,255)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004391c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf70a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mixedres2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
